[2023-07-24 12:05:54,682] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:05:54,850] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:05:54,859] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:05:54,863] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-07-24 12:05:54,865] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:05:55,019] {taskinstance.py:1377} INFO - Executing <Task(PostgresOperator): move_data_to_another_table> on 2023-07-24 11:00:00+00:00
[2023-07-24 12:05:55,116] {standard_task_runner.py:52} INFO - Started process 4608 to run task
[2023-07-24 12:05:55,153] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl_dag', 'move_data_to_another_table', 'scheduled__2023-07-24T11:00:00+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpw1pmfh8n', '--error-file', '/tmp/tmpucuk_co3']
[2023-07-24 12:05:55,164] {standard_task_runner.py:80} INFO - Job 65: Subtask move_data_to_another_table
[2023-07-24 12:05:55,570] {task_command.py:370} INFO - Running <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [running]> on host c03236539c84
[2023-07-24 12:05:56,290] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_dag
AIRFLOW_CTX_TASK_ID=move_data_to_another_table
AIRFLOW_CTX_EXECUTION_DATE=2023-07-24T11:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-24T11:00:00+00:00
[2023-07-24 12:05:56,352] {base.py:68} INFO - Using connection ID 'postgres://cazwrmravtstuq:***@ec2-54-234-13-16.compute-1.amazonaws.com:5432/d7ojfso4s2fmat' for task execution.
[2023-07-24 12:05:56,939] {dbapi.py:213} INFO - Running statement: INSERT INTO public.fraudtest_new (trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction) SELECT trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction FROM real_time_data;, parameters: None
[2023-07-24 12:05:57,110] {dbapi.py:221} INFO - Rows affected: 5
[2023-07-24 12:05:57,331] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_dag, task_id=move_data_to_another_table, execution_date=20230724T110000, start_date=20230724T120554, end_date=20230724T120557
[2023-07-24 12:05:57,460] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-07-24 12:05:57,626] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-07-24 12:05:57,696] {dagrun.py:562} INFO - Marking run <DagRun etl_dag @ 2023-07-24 11:00:00+00:00: scheduled__2023-07-24T11:00:00+00:00, externally triggered: False> successful
[2023-07-24 12:05:57,699] {dagrun.py:622} INFO - DagRun Finished: dag_id=etl_dag, execution_date=2023-07-24 11:00:00+00:00, run_id=scheduled__2023-07-24T11:00:00+00:00, run_start_date=2023-07-24 12:04:16.386803+00:00, run_end_date=2023-07-24 12:05:57.698891+00:00, run_duration=101.312088, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-24 11:00:00+00:00, data_interval_end=2023-07-24 12:00:00+00:00, dag_hash=d6d146d75588f0e96576fdf600bafaf7
[2023-07-24 12:11:44,863] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:11:44,900] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:11:44,903] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:11:44,906] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-07-24 12:11:44,909] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:11:44,983] {taskinstance.py:1377} INFO - Executing <Task(PostgresOperator): move_data_to_another_table> on 2023-07-24 11:00:00+00:00
[2023-07-24 12:11:45,000] {standard_task_runner.py:52} INFO - Started process 4828 to run task
[2023-07-24 12:11:45,024] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl_dag', 'move_data_to_another_table', 'scheduled__2023-07-24T11:00:00+00:00', '--job-id', '78', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpb34jrb11', '--error-file', '/tmp/tmp0jnu1se4']
[2023-07-24 12:11:45,028] {standard_task_runner.py:80} INFO - Job 78: Subtask move_data_to_another_table
[2023-07-24 12:11:45,369] {task_command.py:370} INFO - Running <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [running]> on host c03236539c84
[2023-07-24 12:11:45,813] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_dag
AIRFLOW_CTX_TASK_ID=move_data_to_another_table
AIRFLOW_CTX_EXECUTION_DATE=2023-07-24T11:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-24T11:00:00+00:00
[2023-07-24 12:11:45,853] {base.py:68} INFO - Using connection ID 'postgres://cazwrmravtstuq:***@ec2-54-234-13-16.compute-1.amazonaws.com:5432/d7ojfso4s2fmat' for task execution.
[2023-07-24 12:11:46,457] {dbapi.py:213} INFO - Running statement: INSERT INTO public.fraudtest_new (trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction) SELECT trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction FROM real_time_data;, parameters: None
[2023-07-24 12:11:46,654] {dbapi.py:221} INFO - Rows affected: 5
[2023-07-24 12:11:46,831] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_dag, task_id=move_data_to_another_table, execution_date=20230724T110000, start_date=20230724T121144, end_date=20230724T121146
[2023-07-24 12:11:46,976] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-07-24 12:11:47,108] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-07-24 12:16:31,931] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:16:32,003] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [queued]>
[2023-07-24 12:16:32,012] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:16:32,013] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-07-24 12:16:32,014] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-07-24 12:16:32,112] {taskinstance.py:1377} INFO - Executing <Task(PostgresOperator): move_data_to_another_table> on 2023-07-24 11:00:00+00:00
[2023-07-24 12:16:32,165] {standard_task_runner.py:52} INFO - Started process 4996 to run task
[2023-07-24 12:16:32,223] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl_dag', 'move_data_to_another_table', 'scheduled__2023-07-24T11:00:00+00:00', '--job-id', '85', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp4w66b75i', '--error-file', '/tmp/tmpnqutinfq']
[2023-07-24 12:16:32,241] {standard_task_runner.py:80} INFO - Job 85: Subtask move_data_to_another_table
[2023-07-24 12:16:32,609] {task_command.py:370} INFO - Running <TaskInstance: etl_dag.move_data_to_another_table scheduled__2023-07-24T11:00:00+00:00 [running]> on host c03236539c84
[2023-07-24 12:16:33,421] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_dag
AIRFLOW_CTX_TASK_ID=move_data_to_another_table
AIRFLOW_CTX_EXECUTION_DATE=2023-07-24T11:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-24T11:00:00+00:00
[2023-07-24 12:16:33,616] {base.py:68} INFO - Using connection ID 'postgres://cazwrmravtstuq:***@ec2-54-234-13-16.compute-1.amazonaws.com:5432/d7ojfso4s2fmat' for task execution.
[2023-07-24 12:16:34,227] {dbapi.py:213} INFO - Running statement: INSERT INTO public.fraudtest_new (trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction) SELECT trans_date_trans_time, cc_num, merchant, category, amt, first, last, gender, street, city, state, zip, lat, long, city_pop, job, dob, trans_num, unix_time, merch_lat, merch_long, is_fraud, prediction FROM real_time_data;, parameters: None
[2023-07-24 12:16:34,404] {dbapi.py:221} INFO - Rows affected: 5
[2023-07-24 12:16:34,743] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_dag, task_id=move_data_to_another_table, execution_date=20230724T110000, start_date=20230724T121631, end_date=20230724T121634
[2023-07-24 12:16:34,929] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-07-24 12:16:35,723] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
